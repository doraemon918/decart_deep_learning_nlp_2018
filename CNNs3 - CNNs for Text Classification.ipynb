{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "cfg.gpu_options.per_process_gpu_memory_fraction=0.333\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "import os\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATADIR = '/home/jovyan/DATA/keras_cat_dog/data'\n",
    "import getpass\n",
    "if getpass.getuser() == 'alec':\n",
    "    EMBEDDINGS_PATH = '/Users/alec/Data/glove.6B/glove.6B.200d.txt'\n",
    "    MODELDIR = './saved_models'\n",
    "else:\n",
    "    EMBEDDINGS_PATH = os.path.join(os.path.expanduser('~'), 'DATA/DeepLearning/data/glove.6B.200d.txt')\n",
    "    MODELDIR = os.path.join(os.path.expanduser('~'), 'DATA/DeepLearning/saved_models')\n",
    "\n",
    "assert os.path.exists(EMBEDDINGS_PATH)\n",
    "assert os.path.exists(MODELDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000 # number of words to consider as features\n",
    "MAX_SEQUENCE_LENGTH = 500 # cut texts after this number of words (among top max_features most common words)\n",
    "BATCH_SIZE = 128\n",
    "EMBEDDING_DIM = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks for Text Classification\n",
    "\n",
    "#### @author Alec Chapman\n",
    "\n",
    "Adapted from examples shown in [Deep Learrning with Python](https://www.manning.com/books/deep-learning-with-python) by Francois Chollet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using CNNs with Text\n",
    "CNNs are typically associated with computer vision. They have been shown to offer dramatic improvements in image classification, as shown by ImageNet.\n",
    "\n",
    "CNNs can also be used for some NLP tasks, particularly text classification, which is the task of classifying texts into two or more categories. Although they haven't given the same boost in performance to NLP as they have to computer vision, they can still be used as an effective machine learning algorithm. In this notebook, we will:\n",
    "\n",
    "* Look at a popular (non-biomedical)* dataset and NLP task\n",
    "* Train a CNN for sentiment analysis\n",
    "* Compare a CNN using pretrained word embeddings\n",
    "\n",
    "\\* Note: Deep learning models need lots of data. Since this is a supervised task, we need lots of *labeled* data. For this reason, we aren't going to be using Biomedical tasks as examples, but the concepts can be transferred to any field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis - IMDB Dataset\n",
    "*Sentiment Analysis* is a popular NLP classification task. In sentiment analysis, we are looking at a piece of text and trying to determine what emotion the text is expressing. It is often binary, which means a text can be either **positive** or **negative**.\n",
    "\n",
    "Reviews are an excellent example of texts that can be used for this task. A popular dataset is the IMDB dataset, which has 50,000 movie reviews, split between positive and negative. Our task will be to predict whether a review is positive (the reviewer liked the movie) or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_orig, y_train), (x_test_orig, y_test) = imdb.load_data(num_words=MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what our data looks like. First, here's what it looks like when we load it from keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`y` is fairly straightforward: 0 means negative and 1 means positive. But what does x mean? \n",
    "\n",
    "Let's consider the first data point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x_train_orig[0]\n",
    "print(len(x0))\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of x is a list of integers. The first row has a length of 106. What do these integers mean?\n",
    "\n",
    "Each number is the index for a particular word. A text is transformed from strings to integers. Remember how we limited our number of features to 10,000 words? That's the length of our vocabulary, and any words outside of that vocabulary will just be ignored.\n",
    "\n",
    "Each list of numbers is called a **sequence**, and sequences are primarily what we'll be dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = imdb.get_word_index()\n",
    "print(len(word_index))\n",
    "for word in ['hello', 'world']:\n",
    "    print(word, word_index[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the data actually looks like. Before we loaded the data, the string reports had already been preprocessed and mapped from strings (words) to integers (indices). To see the data in a (somewhat) human-readable form, we'll write a function `inverse_transform` that reverses this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(seq):\n",
    "    # word_index is a dictionary mapping words to an integer index\n",
    "    # We reverse it, mapping integer indices to words\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "    # We decode the review; note that our indices were offset by 3\n",
    "    # because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\".\n",
    "    decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in seq])\n",
    "    \n",
    "    return decoded_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_idx = list(y_train).index(0)\n",
    "pos_idx = list(y_train).index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a positive review\n",
    "negative_decoded_review = inverse_transform(x_train_orig[neg_idx])\n",
    "    \n",
    "# And a negative review\n",
    "positive_decoded_review = inverse_transform(x_train_orig[pos_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(negative_decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positive_decoded_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b. More Data Processing\n",
    "\n",
    "As part of the next step, we'll do a bit more data processing.\n",
    "\n",
    "The first thing to consider is how long each sequence is. With our Cats vs. Dogs classifier, each image was resized to be the same size and shape. Keras expects data to be formatted like this. Let's look at how long our reviews are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lengths = [len(row) for row in x_train_orig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: {}\".format(np.mean(review_lengths)))\n",
    "print(\"Standard Deviation: {}\".format(np.std(review_lengths)))\n",
    "print(\"Max: {}\".format(max(review_lengths)))\n",
    "print(\"Min: {}\".format(min(review_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(review_lengths, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, most reviews are around 200 words long. There's a long tail of some more long-winded reviews, and a few very short ones as well.\n",
    "\n",
    "We'll have to normalize the sequences so that each one is the same length. We'll do this two ways: for long reviews, we'll cut them down using the parameter `MAX_SEQUENCE_LENGTH`, and for any reviews shorter than that number, we'll \"pad\" them by adding 0's to the beginning of those shorter reviews: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train_orig), 'train sequences')\n",
    "print(len(x_test_orig), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train_orig, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "x_test = sequence.pad_sequences(x_test_orig, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sequence is now only 500 words long. Let's look at what our earlier negative review looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inverse_transform(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_idx, longest_review = max(enumerate(x_train_orig), key=lambda x:len(x[1]))\n",
    "len(longest_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_review_shortened = x_train[longest_idx]\n",
    "print(inverse_transform(longest_review_shortened))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Train a CNN for Sentiment Analysis\n",
    "\n",
    "In the previous notebooks, we saw how CNNs are used with images for computer vision: Convolutional layers are performed across two dimensions (height, width). Different kernels are applied across small segments of the image, which allows the model to focus on particular features like edges, curves, shapes, faces, etc.\n",
    "\n",
    "The basic idea of using a CNN with text is similar: Kernels will be applied to small segments of the input data. This time, it will only be **1-dimensional**, across the length of the sentence. \n",
    "\n",
    "Here's a diagram of a CNN for sentence classification:\n",
    "\n",
    "![CNN with sentence](./images/cnn_sentence.jpeg)\n",
    "\n",
    "Let's step through each piece of it and look at a Keras implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer - Representing a sequence of words\n",
    "![Input Sentence](./images/sentence_input.png)\n",
    "\n",
    "A sentence is represented as a sequence of words. In our data, each word has an index. This number will then be mapped to a **word embedding vector**. Here,*n* represents the number of words and *k* represents the dimensionality of the vector.\n",
    "\n",
    "We'll later look at how to use pretrained word embeddings. But Keras also lets you train embeddings \"on the fly\" by using an `Embedding` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding(input_dim=MAX_FEATURES, # Vocabulary size\n",
    "            output_dim=EMBEDDING_DIM, # Embedding dimension - 200\n",
    "            input_length=MAX_SEQUENCE_LENGTH) # How many words can be in a single input/sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Dimensional Convolutional Layer\n",
    "![Example of Convolution](./images/convolution_text.png)\n",
    "Convolution is performed across the sentence, looking at chunks of the sentence at a time. You could compare this to n-grams in traditional language models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.Conv1D(filters=32, kernel_size=7, strides=1, activation='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling\n",
    "![Max Pooling](./images/max_pooling_text.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.MaxPooling1D(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected and output layers\n",
    "Just like in our cats vs. dogs model, we flatten the inputs, add a fully connected layer, and use an output layer. This is once again a binary classification problem, so our final layer has a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flatten()\n",
    "layers.Dense(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model\n",
    "Here's what our full model looks like. Once again, we'll be loading in a pretrained model to evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name='model_no_pretrained_embeddings')\n",
    "model.add(Embedding(input_dim=MAX_FEATURES,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "#                     batch_size=BATCH_SIZE,\n",
    "                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(Flatten())\n",
    "model.add(layers.Dense(1))\n",
    "\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(x_train, y_train, epochs=10, \n",
    "#                     batch_size=BATCH_SIZE, \n",
    "#                   validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the pretrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(os.path.join(MODELDIR, 'imdb.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to evaluate directly, run this cell\n",
    "# Otherwise we'll look at logged scores below\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "We'll load the `history` object that was created by training and contains the training/validation accuracies. Let's plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the accuracy info\n",
    "with open('logs/imdb_history.pkl', 'rb') as f:\n",
    "    h = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h['acc'], marker='.', linestyle='dotted', alpha=0.4, label='IMDB Training Acc')\n",
    "plt.plot(h['val_acc'], marker='.', label=\"IMDB Validation Acc\")\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylim((0.5, 0.92))\n",
    "plt.legend(loc='upper center', ncol=2,mode='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the performance peaks around 3 or 4 epochs. Here's another model that was trained for that many epochs to maximize performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('saved_models/imdb_4_epochs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try using our sentiment classifier! Here are two reviews of *Mamma Mia 2* from Rotten Tomatoes: One is \"fresh\" (positive) the other \"rotten\" (negative). Let's transform these reviews so that our model can predict on them and see if it gets them right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresh_mamma_mia = \"\"\"\n",
    "Even better than the original, creating a great backstory and bringing a touching and gratifying closure to the \\\n",
    "mother-daughter story of Mamma Mia. Excellent choreography, catchy songs and beautiful performances by Lilly James and \\\n",
    "Amanda Seyfried, plus just the right amount of humor and sentimentality.\n",
    "\"\"\"\n",
    "\n",
    "rotten_mamma_mia = \"\"\"\n",
    "As a film, it was overly reliant on the audiences nostalgia, incorporating the lower quality Abba songs which \\\n",
    "remind you how much more you wanted to watch the original. The original Swedish script echoes in this, with much \\\n",
    "of the dialogue being poorly localised and therefore making very little sense at all. \\\n",
    "A very basic and safe plot is used, making it evident that this film was only made as a cash grab from a fanbase still \\\n",
    "in love with the original\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_reviews(texts, model):\n",
    "    x = np.array([prepare_text(text) for text in texts])\n",
    "    x = sequence.pad_sequences(x, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    pred = model.predict_classes(x)\n",
    "    return [\"fresh\" if p == 1 else \"rotten\" for p in pred ]\n",
    "\n",
    "def prepare_text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    seq = words2seq(tokens)\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def words2seq(words):\n",
    "    seq = []\n",
    "    for w in words:\n",
    "        idx = word_index.get(w)\n",
    "        if idx is not None and idx < MAX_FEATURES:  # 2 is the placeholder for out-of-vocabulary\n",
    "            seq.append(idx + 3)\n",
    "        else:\n",
    "            seq.append(2)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_reviews([fresh_mamma_mia, rotten_mamma_mia],\n",
    "                model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Add pretrained word embedings\n",
    "As we've discussed, deep learning is **slow** and takes **a lot** of data. To ease this, we can try utilizing models that have already been trained. This is called **transfer learning**. In computer vision models, this entails taking a model that's been trained on a large number of images, such as AlexNet or ResNet, and retraining the last few layers so that they are configured towards your task. See [this blog](https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/) for an example of that.\n",
    "\n",
    "When working with text, this means taking pretrained word embeddings and using them as the first layer of our model. We already looked at some embeddings using TensorFlow's [Embeddings Project](https://projector.tensorflow.org/). We'll take a different set of word embeddings, trained using the [GloVe algorithm](https://nlp.stanford.edu/projects/glove/) and try initializing our model with them. Let's see if they boost our performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "First, we'll process all of the vectors contained in the GloVe file, map them to our word index, and then create a matrix of vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(EMBEDDINGS_PATH)\n",
    "embeddings_index = {}\n",
    "num_lines = 399999\n",
    "for i, line in enumerate(f):\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"{i}/{num_lines}\")\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((MAX_FEATURES, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < MAX_FEATURES: # words with an index larger than this will be excluded\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we saw earlier when we looked at word embeddings, embeddings can be used to semantic similarity. Let's test this with these embeddings: We'll take two words that we expect to be very similar and measure the distance between them; we'll then take a third word that we expect to be very different and see if it's farther away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movie_vec = embedding_matrix[word_index.get('movie')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_vec = embedding_matrix[word_index.get('film')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banana_vec = embedding_matrix[word_index.get('banana')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "cosine(movie_vec, film_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(movie_vec, banana_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model w/ Pretrained Embeddings\n",
    "We take our newly constructed `embedding_matrix` and supply it to the `Embedding Layer` using the `weights` argument. We'll also freeze so that it doesn't adjust the weights during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_emb = Sequential(name='model_pretrained_embeddings')\n",
    "model_pretrained_emb.add(\n",
    "    Embedding(input_dim=MAX_FEATURES,\n",
    "                    output_dim=EMBEDDING_DIM,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                    trainable=False))\n",
    "model_pretrained_emb.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model_pretrained_emb.add(layers.MaxPooling1D(5))\n",
    "model_pretrained_emb.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model_pretrained_emb.add(layers.MaxPooling1D(5))\n",
    "model_pretrained_emb.add(Flatten())\n",
    "model_pretrained_emb.add(layers.Dense(1))\n",
    "\n",
    "model_pretrained_emb.compile(optimizer=RMSprop(lr=1e-4),\n",
    " loss='binary_crossentropy',\n",
    " metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# history_pretrained_emb = model_pretrained_emb.fit(x_train, y_train,\n",
    "#                          validation_data=(x_test, y_test),\n",
    "#                          epochs=10, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained_emb = models.load_model('saved_models/imdb_pretrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logs/history_pretrained.pkl', 'rb') as f:\n",
    "    h_pre = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = {'imdb': h,\n",
    "            'imdb_pretrained': h_pre}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two model's performances\n",
    "fig, ax = plt.subplots()\n",
    "x = range(10)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "i = 0\n",
    "for name, history in histories.items():\n",
    "    ax.plot(history['acc'], marker='.', linestyle='dotted', label=\"{} train acc\".format(name, alpha=0.4), color=colors[i])\n",
    "    ax.plot(history['val_acc'], marker='.', label=\"{} val acc\".format(name))\n",
    "    i += 1\n",
    "    \n",
    "    \n",
    "# ax.set_title('CNN Sentiment Analysis Validation Accuracy')\n",
    "ax.set_xlabel('# epochs')\n",
    "fig.legend(loc='upper center', ncol=2,mode='expand')\n",
    "\n",
    "\n",
    "\n",
    "# plot_scores(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Compare a Traditional Machine Learning Baseline\n",
    "Deep Learning comes with a lot of costs - you need lots of data and lots of computational power. When considering using deep learning for a task, it's always important to ask the question of whether using all those extra resources is justified.\n",
    "\n",
    "To try this, we'll compare a simple traditional machine learning baseline. We won't put too much effort into optimizing it, although you could take it and try to improve it. For now, we just want to see if the work we did above paid off.\n",
    "\n",
    "Here are the steps we'll take:\n",
    "- Convert the data from sequences of word indices to a bag of words (BOW) document-level representation\n",
    "- Train a Random Forest Classifier with default settings\n",
    "- Compare accuracy with deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqs2bow(x, vectorizer=None):\n",
    "    \"\"\"\n",
    "    Takes a list of sequences\n",
    "    and converts them into a bag of words vector.\n",
    "    \"\"\"\n",
    "    x_dicts = []\n",
    "    for seq in x:\n",
    "        d = {}\n",
    "        for word in seq:\n",
    "            if word not in d:\n",
    "                d[word] = 0\n",
    "            d[word] += 1\n",
    "        x_dicts.append(d)\n",
    "        \n",
    "    if not vectorizer:\n",
    "        vectorizer = DictVectorizer()\n",
    "        x = vectorizer.fit_transform(x_dicts)\n",
    "    else:\n",
    "        x = vectorizer.transform(x_dicts)\n",
    "    \n",
    "    return x, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new, vectorizer = seqs2bow(x_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_new, vectorizer = seqs2bow(x_test_orig, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = clf.predict(x_train_new)\n",
    "bow_train_acc = accuracy_score(y_train, pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(x_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_val_acc = accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all three models\n",
    "fig, ax = plt.subplots()\n",
    "x = range(10)\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "i = 0\n",
    "for name, history in histories.items():\n",
    "    ax.plot(history['acc'], marker='.', linestyle='dotted', label=\"{} train acc\".format(name, alpha=0.4), color=colors[i])\n",
    "    ax.plot(history['val_acc'], marker='.', label=\"{} val acc\".format(name))\n",
    "    i += 1\n",
    "    \n",
    "# Add a horizontal line showing the BOW accuracy\n",
    "ax.hlines(y=bow_train_acc, xmin=0, xmax=10, label='BOW training accuracy', color=colors[i], linestyle='dotted')\n",
    "ax.hlines(y=bow_val_acc, xmin=0, xmax=10, label='BOW validation accuracy', color=colors[i], alpha=0.4)\n",
    "    \n",
    "# ax.set_title('CNN Sentiment Analysis Validation Accuracy')\n",
    "ax.set_xlabel('# epochs')\n",
    "fig.legend(loc='upper center', ncol=3,mode='expand')\n",
    "\n",
    "\n",
    "\n",
    "# plot_scores(histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def score_table():\n",
    "    df = pd.DataFrame(columns=['Model Name', 'Max Training Accuracy', 'Max Validation Accuracy'],\n",
    "                     data=[\n",
    "                         {'Model Name': \"IMDB\", \n",
    "                          \"Max Training Accuracy\": max(histories['imdb']['acc']),\n",
    "                          'Max Validation Accuracy': max(histories['imdb']['val_acc'])\n",
    "                         },\n",
    "                     {\"Model Name\":'IMDB Pretrained Embeddings', \n",
    "                     \"Max Training Accuracy\": max(histories['imdb_pretrained']['acc']),\n",
    "                     \"Max Validation Accuracy\": max(histories['imdb_pretrained']['val_acc'])},\n",
    "                     {'Model Name': 'Random Forest BOW',\n",
    "                     \"Max Training Accuracy\": bow_train_acc,\n",
    "                      \"Max Validation Accuracy\": bow_val_acc\n",
    "                     }])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this case, deep learning clearly shows some good improvement. The first model - with no pretrained embeddings - offers pretty solid performance without too much overfitting. When we add pretrained embeddings, it does start to overfit quite a bit. Some more regularization (or debugging) could help with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
