{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "cfg.gpu_options.per_process_gpu_memory_fraction=0.333\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs for Computer Vision\n",
    "## II. Using a pretrained model\n",
    "\n",
    "#### @author Alec Chapman\n",
    "\n",
    "This tutorial was adapted from [this keras blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "\n",
    "\n",
    "The data comes from a [Kaggle competition to classify images as being cats or dogs. The data can be downloaded [here](https://www.kaggle.com/c/dogs-vs-cats/data) after signing into Kaggle (either via a Kaggle account or Google, Facebook, or Yahoo!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import some modules needed for our tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the data directory paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DATADIR = '/home/jovyan/DATA/keras_cat_dog/data'\n",
    "import getpass\n",
    "if getpass.getuser() == 'alec':\n",
    "    DATADIR = \"./data_alec/cats_vs_dogs/\"\n",
    "    MODELDIR = './saved_models'\n",
    "else:\n",
    "    DATADIR = os.path.join(os.path.expanduser('~'), 'DATA/DeepLearning/data/cats_vs_dogs/')\n",
    "    MODELDIR = os.path.join(os.path.expanduser('~'), 'DATA/DeepLearning/saved_models')\n",
    "TRAINDIR = os.path.join(DATADIR, 'train')\n",
    "VALDIR = os.path.join(DATADIR, 'val')\n",
    "assert os.path.exists(DATADIR)\n",
    "assert os.path.exists(MODELDIR)\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview - Pretrained Models\n",
    "In the last notebook, we saw how we can create a Convolutional Neural Network from scratch and train it on our data. However, training can take a long time, and you don't want to have to train every time you want to make predictions with your model.\n",
    "\n",
    "Keras makes it very easy to load in pretrained models. We'll load in a model that was trained using our data and use our validation data to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !ls /srv/DATA/keras_cat_dog/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(MODELDIR, 'cats_vs_dogs.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "We're finally ready to evaluate our model on our validation set! Like in the first notebook, we'll create an image generator that will load images in, reshape them, normalize the pixel values, and pass them along to our model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255) \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        VALDIR,\n",
    "        target_size=(227, 227),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate_generator(validation_generator, steps=800//batch_size, verbose=1)\n",
    "print(\"Accuracy: {} Loss: {}\".format(acc, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize our predictions. The left column will show all of the images that our model thinks are cats, the right will show all of the images that our model thinks are dogs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(validation_generator)\n",
    "y_pred = model.predict_classes(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ncols = 2\n",
    "nimg = x_batch.shape[0]\n",
    "\n",
    "fig = plt.figure(figsize=(18,9))\n",
    "for i in range(len(x_batch)):\n",
    "    x = x_batch[i]\n",
    "    y = y_batch[i]\n",
    "    ax = plt.subplot2grid((nimg//ncols+1, ncols), (i//ncols,y_pred[i][0]))\n",
    "    ax.imshow(x)\n",
    "    #img = array_to_img(x)\n",
    "    #img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the training and validation accuracies at each stage in training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and validation accuracy history\n",
    "with open('logs/history_cats_vs_dogs.pkl', 'rb') as f:\n",
    "    h = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(h['acc'], marker='.', linestyle='dotted', alpha=0.4, label='Cats Vs. Dogs Train Acc')\n",
    "plt.plot(h['val_acc'], marker='.', label=\"Cats Vs. Dogs Val Acc\")\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylim((0.5, 0.92))\n",
    "plt.legend(loc='upper center', ncol=2,mode='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras's Pretrained Models:\n",
    "Keras has a number of models available that have been trained with ImageNet data, an image recognition challenge that has 1000 classes and large, large training datasets. We can quickly download one of those models and see what it does on a few of our images:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a cat and dog image at random\n",
    "cat = random.choice(glob.glob(os.path.join(TRAINDIR, 'cat', 'cat*')))\n",
    "dog = random.choice(glob.glob(os.path.join(TRAINDIR, 'dog', 'dog*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_cat = image.load_img(cat, target_size=(224, 224))\n",
    "img_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = image.img_to_array(img_cat)\n",
    "x_cat = np.expand_dims(x_cat, axis=0)\n",
    "x_cat = preprocess_input(x_cat)\n",
    "\n",
    "preds = model.predict(x_cat)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dog = image.load_img(dog, target_size=(224, 224))\n",
    "img_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dog = image.img_to_array(img_dog)\n",
    "x_dog = np.expand_dims(x_dog, axis=0)\n",
    "x_dog = preprocess_input(x_dog)\n",
    "\n",
    "preds = model.predict(x_dog)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Intermediate Layers\n",
    "Let's look at how this model is functioning.\n",
    "\n",
    "**Note** - These examples are taken from [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "# Extracts every other models for the first 30 layers, plus two of the later layers:\n",
    "# For some reason this started throwing an error when predicting the first layer\n",
    "layer_outputs = [layer.output for (i, layer) in enumerate(model.layers[1:30]) if i % 2 == 0]\n",
    "\n",
    "# Creates a model that will return these outputs, given the model input:\n",
    "activation_model = models.Model(input=model.input, output=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_intermediate_layers(img_tensor):\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "    for activation_layer in activations:\n",
    "        _,_,_, channels = activation_layer.shape\n",
    "        # Pick a random channel to plot\n",
    "        channel_to_plot = random.choice(range(channels))\n",
    "        plt.matshow(activation_layer[0, :, :, channel_to_plot], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_intermediate_layers(x_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_intermediate_layers(x_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We can use pretrained models to easily predict using models that were already trained. These models can be made from scratch or be one of a number of pre-existing models. This can allow us to utilize heavy computing resources for training and then be able to predict much more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
